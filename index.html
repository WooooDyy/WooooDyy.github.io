<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zhiheng Xi</title>

    <meta name="author" content="Zhiheng Xi">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon"
          href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p class="name" style="text-align: center;">
                            Zhiheng Xi
                        </p>
                        <p>I am a second-year master student at <a href="https://nlp.fudan.edu.cn/">Fudan NLP Group</a>
                            of <a href="https://cs.fudan.edu.cn/">Computer School, Fudan University</a>,
                            where I work on natural language processing (NLP) and deep learning (DL). I am advised by
                            Prof. <a href="https://guitaowufeng.github.io/">Tao Gui</a>, Prof. <a
                                    href="http://qizhang.info/index.html">Qi Zhang</a>, and Prof. <a
                                    href="https://xuanjing-huang.github.io/">Xuanjing Huang</a>.
                            Previously, I got my bachelor's degree from <a href="https://www.nju.edu.cn/">Nanjing
                                University</a>, advised by Prof. Jia Liu.
                        </p>

                        <!-- <p>
                          At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
                        </p> -->
                        <p style="text-align:center">
                            <a href="mailto:zhxi22@m.fudan.edu.cn">Email</a> &nbsp;/&nbsp;
                            <!-- <a href="TODO">CV</a> &nbsp;/&nbsp; -->
                            <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                            <a href="https://scholar.google.com.hk/citations?user=zSVLkqAAAAAJ">Google Scholar</a>
                            &nbsp;/&nbsp;
                            <a href="https://www.zhihu.com/people/fang-kong-43">Zhihu</a> &nbsp;/&nbsp;
                            <a href="https://github.com/WooooDyy">Github</a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/xizhiheng.jpg"><img style="width:60%;max-width:100%" alt="profile photo"
                                                            src="images/xizhiheng.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <h2>Research</h2>
                        <p>
                            I have general interest in deep learning, natural language processing, and robust machine
                            learning. Recently, I focus my research on on large language models (LLMs) and LLM-based
                            agents.
                            <!-- Representative papers are <span class="highlight">highlighted</span>. -->
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>


                <!-- <tr onmouseout="llm_agent_survey_stop()" onmouseover="llm_agent_survey_start()"  bgcolor="#ffffd0"> -->
                <tr onmouseout="llm_agent_survey_stop()" onmouseover="llm_agent_survey_start()">
                    <td style="padding:20px;width:30%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='llm_agent_survey_image'>
                                <img src='images/llm_agent_survey.jpg' width="190">
                            </div>
                            <img src='images/llm_agent_survey.jpg' width="190">
                        </div>
                        <script type="text/javascript">
                            function llm_agent_survey_start() {
                                document.getElementById('llm_agent_survey_image').style.opacity = "1";
                            }

                            function llm_agent_survey_stop() {
                                document.getElementById('llm_agent_survey_image').style.opacity = "0";
                            }

                            llm_agent_survey_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2309.07864">
                            <span class="papertitle">The Rise and Potential of Large Language Model Based Agents: A Survey</span>
                        </a>
                        <br>
                        <strong>Zhiheng Xi</strong>, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming
                        Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Qin
                        Liu, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan
                        Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing
                        Huang, Tao Gui
                        <br>
                        <br>
                        <!--          preprint.-->
                        <!--           <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>-->
                        <em>Preprint.</em> September, 2023

                        <br>
                        <a href="https://github.com/WooooDyy/LLM-Agent-Paper-List">project page</a>
                        /
                        <!-- <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a> -->

                        <a href="https://arxiv.org/abs/2309.07864">paper</a>
                        <p></p>
                        <p>

                            In this paper, we provide a comprehensive survey of LLM-based agents with <strong>86
                            pages</strong>.
                            We start by tracing the concept of agents from its philosophical origins to its development
                            in AI.
                            Next, the main body includes the construction of LLM-based agents, its extensive
                            applications, and the essential concept of Agent society.
                            <!--          Next we present a conceptual framework for LLM-based agents, comprising three main components: brain, perception, and action.-->
                            <!--          Subsequently, we explore the applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation.-->
                            <!--          Following this, we delve into agent societies-->
                            Finally, we discuss a range of key topics and open problems within the field, e.g., scaling
                            number of agentsand Agent-as-a-service.

                        </p>
                    </td>
                </tr>


                <tr onmouseout="self_polish_stop()" onmouseover="self_polish_start()">
                    <td style="padding:20px;width:30%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='self_polish_image'>
                                <img src='images/self_polish.jpg' width="190">
                            </div>
                            <img src='images/self_polish.jpg' width="190">
                        </div>
                        <script type="text/javascript">
                            function self_polish_start() {
                                document.getElementById('self_polish_image').style.opacity = "1";
                            }

                            function self_polish_stop() {
                                document.getElementById('self_polish_image').style.opacity = "0";
                            }

                            self_polish_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2305.14497">
                            <span class="papertitle">Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement</span>
                        </a>
                        <br>
                        <strong>Zhiheng Xi</strong>, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao, Jia Liu, Tao Gui,
                        Qi Zhang, Xuanjing Huang
                        <br>
                        <em>Preprint.</em> May, 2023

                        <!-- <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
                        <br>
                        <a href="https://github.com/WooooDyy/Self-Polish">codes</a>
                        /
                        <!-- <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a> -->

                        <a href="https://arxiv.org/abs/2305.14497">paper</a>
                        <p></p>
                        <p>
                            Different from previous work like Chain-of-Thought (CoT) which enhance LLMs' reasoning
                            performance from the <strong> answer/reasoning side </strong>,
                            we start from the <strong> problem side </strong> and propose Self-Polish (SP).
                            It is a novel method that facilitates the model‚Äôs reasoning by guiding it to progressively
                            refine the given problems to be more comprehensible and solvable.
                        </p>
                    </td>
                </tr>


                <tr onmouseout="copate_stop()" onmouseover="copate_start()">
                    <td style="padding:20px;width:30%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='copate_image'>
                                <img src='images/copate.jpg' width="190">
                            </div>
                            <img src='images/copate.jpg' width="190">
                        </div>
                        <script type="text/javascript">
                            function copate_start() {
                                document.getElementById('copate_image').style.opacity = "1";
                            }

                            function copate_stop() {
                                document.getElementById('copate_image').style.opacity = "0";
                            }

                            copate_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://aclanthology.org/2023.findings-acl.759/">
                            <span class="papertitle">Connectivity Patterns are Task Embeddings</span>
                        </a>
                        <br>
                        <strong>Zhiheng Xi</strong>, Rui Zheng, Yuansen Zhang, XuanJing Huang, Zhongyu Wei, Minlong
                        Peng, Mingming Sun, Qi Zhang, Tao Gui
                        <br>
                        <em>ACL 2023 Findings.</em>

                        <!-- <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
                        <br>
                        <a href="https://github.com/WooooDyy/CoPaTE">codes</a>
                        /
                        <!-- <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a> -->

                        <a href="https://aclanthology.org/2023.findings-acl.759/">paper</a>
                        <p></p>
                        <p>
                            In this work, we draw inspiration from the operating mechanism of deep neural networks
                            (DNNs) and biological brains,
                            where neuronal activations are sparse and task-specific,
                            and we use the connectivity patterns of neurons as a unique identifier (<strong>Task
                            Embeddings</strong>) associated with the task.
                            Experiments show that our method consistently outperforms other baselines in predicting
                            inter-task transferability across data regimes and transfer settings,
                            while keeping high efficiency in computation and storage.
                        </p>
                    </td>
                </tr>

                <tr onmouseout="early_robust_stop()" onmouseover="early_robust_start()">
                    <td style="padding:20px;width:30%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='early_robust_image'>
                                <img src='images/early_robust.jpg' width="190">
                            </div>
                            <img src='images/early_robust.jpg' width="190">
                        </div>
                        <script type="text/javascript">
                            function early_robust_start() {
                                document.getElementById('early_robust_image').style.opacity = "1";
                            }

                            function early_robust_stop() {
                                document.getElementById('early_robust_image').style.opacity = "0";
                            }

                            early_robust_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://aclanthology.org/2022.emnlp-main.569/">
                            <span class="papertitle">Efficient Adversarial Training with Robust Early-Bird Tickets</span>
                        </a>
                        <br>
                        <strong>Zhiheng Xi</strong>, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang
                        <br>
                        <em>EMNLP 2022.</em>

                        <!-- <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
                        <br>
                        <a href="https://github.com/WooooDyy/early_robust">codes</a>
                        /
                        <!-- <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a> -->

                        <a href="https://aclanthology.org/2022.emnlp-main.569/">paper</a>
                        <p></p>
                        <p>
                            Adversarial training, a strong algorithm to enhance model robustness, is typically more
                            expensive than traditional fine-tuning because of the necessity to generate adversarial
                            examples via gradient descent.
                            Delving into the optimization process of adversarial training,
                            we find that robust connectivity patterns emerge in the early training phase (typically
                            0.15~0.3 epochs), far before parameters converge.
                            Inspired by this finding, we dig out <strong>robust early-bird tickets (i.e.,
                            subnetworks)</strong> to develop an efficient adversarial training method.
                        </p>
                    </td>
                </tr>

                <tr onmouseout="robust_data_stop()" onmouseover="robust_data_start()">
                    <td style="padding:20px;width:30%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id='robust_data_image'>
                                <img src='images/robust_data.jpg' width="190">
                            </div>
                            <img src='images/robust_data.jpg' width="190">
                        </div>
                        <script type="text/javascript">
                            function robust_data_start() {
                                document.getElementById('robust_data_image').style.opacity = "1";
                            }

                            function robust_data_stop() {
                                document.getElementById('robust_data_image').style.opacity = "0";
                            }

                            robust_data_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://aclanthology.org/2023.findings-acl.146/">
                            <span class="papertitle">Characterizing the Impacts of Instances on Robustness</span>
                        </a>
                        <br>
                        Rui Zheng, <strong>Zhiheng Xi (Co-first Author)</strong>, Qin Liu, Wenbin Lai, Tao Gui, Qi
                        Zhang, Xuanjing Huang, Jin Ma, Ying Shan, Weifeng Ge
                        <br>
                        <em>ACL 2023 Findings.</em>

                        <!-- <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
                        <br>
                        <a href="https://github.com/WooooDyy/robust_data">codes</a>
                        /
                        <!-- <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a> -->

                        <a href="https://aclanthology.org/2023.findings-acl.146/">paper</a>
                        <p></p>
                        <p>
                            Adversarial training, a strong algorithm to enhance model robustness, is typically more
                            expensive than traditional fine-tuning because of the necessity to generate adversarial
                            examples via gradient descent.
                            Delving into the optimization process of adversarial training,
                            we find that robust connectivity patterns emerge in the early training phase (typically
                            0.15~0.3 epochs), far before parameters converge.
                            Inspired by this finding, we dig out <strong>robust early-bird tickets (i.e.,
                            subnetworks)</strong> to develop an efficient adversarial training method.
                        </p>
                    </td>
                </tr>


                <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <!--            <heading>Miscellanea</heading>-->
                                                  <h2>Miscellanea</h2>

                            <ul>
                                <li> I'm passionate about FPS games, including Counter-Strike: Global Offensive (CS:GO)
                                    and CrossFire (CF).
                                </li>
                                <li> I love watching soccer and am a big fan of Mourinho. So now I'm a Roma fan.</li>
                                <li> I also love watching basketball games and my favorite player is Kevin Durant.</li>

                            </ul>
                        </td>
                    </tr>
                    </tbody>
                </table>


                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <!-- <tr>
                      <td>
                        <h2>Miscellanea</h2>
                      </td>
                    </tr>
                  </tbody></table>
                  <table width="100%" align="center" border="0" cellpadding="20"><tbody>

                    <tr>
                      <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                      <td width="75%" valign="center">
                        <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                  <br>
                        <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                        <br>
                        <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
                        <br>
                        <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                        <br>
                        <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                      </td>
                    </tr>
                    <tr>
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src="images/cs188.jpg" alt="cs188">
                      </td>
                      <td width="75%" valign="center">
                        <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                        <br>
                        <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                        <br>
                        <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
                      </td>
                    </tr> -->


                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                        <tr>
                            <td style="padding:20px">
                                <p font-size:small;="">
                                    <br>
                                    <br>
                                </p>
                                <div style="float:left;">
                                    Updated at September 2023
                                </div>
                                <div style="float:right;">
                                    Thanks <a href="https://jonbarron.info">Jon Barron</a> for this fantastic template!
                                </div>
                                <br>
                                <br>
                                <p></p>
                            </td>
                        </tr>
                        </tbody>
                    </table>
                    </td>
                    </tr>
                </table>
</body>
</html>
